ğŸ“Œ AI Chatbot with Local LLM (Ollama)

A full-stack AI chatbot built with Flask, SQLite, Docker, and Ollama, featuring persistent chat sessions, auto-generated titles, and a modern sidebar UI.

This project runs entirely locally using a free LLM (no paid APIs required), with optional OpenAI support for future use.

âœ¨ Features

ğŸ¤– AI chatbot powered by Ollama (LLaMA 3)

ğŸ’¾ Persistent chat history using SQLite

ğŸ—‚ï¸ Sidebar with chat sessions

ğŸ·ï¸ Auto-generated chat titles

ğŸ—‘ï¸ Delete individual chats

ğŸ”„ Restore last session on refresh

âš¡ Typing animation & smooth UI

ğŸ³ Fully Dockerized

ğŸ”Œ Pluggable LLM backend (Ollama now, OpenAI later)

ğŸ›  Tech Stack

Frontend

HTML, CSS, Vanilla JavaScript

Backend

Python (Flask)

SQLite

AI / LLM

Ollama (LLaMA 3)

DevOps

Docker & Docker Compose

ğŸš€ Getting Started (Local)
1ï¸âƒ£ Install Ollama
brew install ollama
ollama run llama3

2ï¸âƒ£ Clone the repo
git clone https://github.com/your-username/ai-chatbot-flask.git
cd ai-chatbot-flask

3ï¸âƒ£ Run with Docker
docker compose up --build

4ï¸âƒ£ Open in browser
http://localhost:8000/ui

ğŸ“‚ Project Structure
ai-chatbot-flask/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ openai_client.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ chat.js
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .env
â””â”€â”€ README.md

ğŸ”® Roadmap (Upcoming Features)

ğŸŒ— Light / Dark themes

ğŸ–¼ï¸ Image upload support

ğŸ“¡ Streaming responses

ğŸ” Authentication

â˜ï¸ Cloud deployment

ğŸ¤ OpenAI model toggle

ğŸ“¸ Screenshots

See screenshots below ğŸ‘‡

ğŸ§‘â€ğŸ’» Author

Vidisha Sodha
Built as a full-stack + AI learning project.